{
 "metadata": {
  "name": "",
  "signature": "sha256:5e8b17f61395ab43f150cc85dbafdafdc232edd157ae952105474241188c86f5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "from picamera import PiCamera\n",
      "from picamera.array import PiRGBArray\n",
      "import tensorflow as tf\n",
      "import argparse\n",
      "import os.path\n",
      "import re\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.image as mpimg\n",
      "%matplotlib inline  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class NodeLookup(object):\n",
      "  \"\"\"Converts integer node ID's to human readable labels.\"\"\"\n",
      "\n",
      "  def __init__(self,\n",
      "               label_lookup_path='./inception/label_map.pbtxt',\n",
      "               uid_lookup_path='./inception/human_label_map.txt'):\n",
      "    if not label_lookup_path:\n",
      "      label_lookup_path = os.path.join(\n",
      "          FLAGS.model_dir, 'imagenet_2012_challenge_label_map_proto.pbtxt')\n",
      "    if not uid_lookup_path:\n",
      "      uid_lookup_path = os.path.join(\n",
      "          FLAGS.model_dir, 'imagenet_synset_to_human_label_map.txt')\n",
      "    self.node_lookup = self.load(label_lookup_path, uid_lookup_path)\n",
      "\n",
      "  def load(self, label_lookup_path, uid_lookup_path):\n",
      "    \"\"\"Loads a human readable English name for each softmax node.\n",
      "\n",
      "    Args:\n",
      "      label_lookup_path: string UID to integer node ID.\n",
      "      uid_lookup_path: string UID to human-readable string.\n",
      "\n",
      "    Returns:\n",
      "      dict from integer node ID to human-readable string.\n",
      "    \"\"\"\n",
      "    if not tf.gfile.Exists(uid_lookup_path):\n",
      "      tf.logging.fatal('File does not exist %s', uid_lookup_path)\n",
      "    if not tf.gfile.Exists(label_lookup_path):\n",
      "      tf.logging.fatal('File does not exist %s', label_lookup_path)\n",
      "\n",
      "    # Loads mapping from string UID to human-readable string\n",
      "    proto_as_ascii_lines = tf.gfile.GFile(uid_lookup_path).readlines()\n",
      "    uid_to_human = {}\n",
      "    p = re.compile(r'[n\\d]*[ \\S,]*')\n",
      "    for line in proto_as_ascii_lines:\n",
      "      parsed_items = p.findall(line)\n",
      "      uid = parsed_items[0]\n",
      "      human_string = parsed_items[2]\n",
      "      uid_to_human[uid] = human_string\n",
      "\n",
      "    # Loads mapping from string UID to integer node ID.\n",
      "    node_id_to_uid = {}\n",
      "    proto_as_ascii = tf.gfile.GFile(label_lookup_path).readlines()\n",
      "    for line in proto_as_ascii:\n",
      "      if line.startswith('  target_class:'):\n",
      "        target_class = int(line.split(': ')[1])\n",
      "      if line.startswith('  target_class_string:'):\n",
      "        target_class_string = line.split(': ')[1]\n",
      "        node_id_to_uid[target_class] = target_class_string[1:-2]\n",
      "\n",
      "    # Loads the final mapping of integer node ID to human-readable string\n",
      "    node_id_to_name = {}\n",
      "    for key, val in node_id_to_uid.items():\n",
      "      if val not in uid_to_human:\n",
      "        tf.logging.fatal('Failed to locate: %s', val)\n",
      "      name = uid_to_human[val]\n",
      "      node_id_to_name[key] = name\n",
      "\n",
      "    return node_id_to_name\n",
      "\n",
      "  def id_to_string(self, node_id):\n",
      "    if node_id not in self.node_lookup:\n",
      "      return ''\n",
      "    return self.node_lookup[node_id]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_classification():\n",
      "    \"\"\"Stream images off the camera and process them.\"\"\"\n",
      "\n",
      "    camera = PiCamera()\n",
      "    camera.resolution = (320, 240)\n",
      "    camera.framerate = 2\n",
      "    raw_capture = PiRGBArray(camera, size=(320, 240))\n",
      "\n",
      "    # Warmup...\n",
      "    time.sleep(2)\n",
      "\n",
      "    # Unpersists graph from file\n",
      "    with tf.gfile.FastGFile(\"./inception/inception.pb\", 'rb') as fin:\n",
      "        graph_def = tf.GraphDef()\n",
      "        graph_def.ParseFromString(fin.read())\n",
      "        _ = tf.import_graph_def(graph_def, name='')\n",
      "\n",
      "    with tf.Session() as sess:\n",
      "        # And capture continuously forever.\n",
      "        softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')\n",
      "        for _, image in enumerate(\n",
      "                camera.capture_continuous(\n",
      "                    raw_capture, format='bgr', use_video_port=True\n",
      "                )\n",
      "            ):\n",
      "           \n",
      "            decoded_image = image.array\n",
      "            imgplot = plt.imshow(decoded_image)\n",
      "            plt.show() \n",
      "           \n",
      "            predictions = sess.run(softmax_tensor, {'DecodeJpeg:0': decoded_image})\n",
      "            predictions = np.squeeze(predictions)\n",
      "            top_k = predictions.argsort()[-3:][::-1]\n",
      "            for node_id in top_k:\n",
      "              human_string = node_lookup.id_to_string(node_id)\n",
      "              score = predictions[node_id]\n",
      "              print('%s (score = %.5f)' % (human_string, score))\n",
      "\n",
      "            # Reset the buffer so we're ready for the next one.\n",
      "            raw_capture.truncate(0)\n",
      "\n",
      "\n",
      "   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "node_lookup = NodeLookup()\n",
      "run_classification()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}